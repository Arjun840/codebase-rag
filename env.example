# Model Configuration
# Code-aware embedding models (recommended for better code understanding):
# - flax-sentence-embeddings/st-codesearch-distilroberta-base (DEFAULT - CodeSearch DistilRoBERTa, 768d)
# - microsoft/codebert-base (CodeBERT, 768d)
# - microsoft/graphcodebert-base (GraphCodeBERT with data flow, 768d)
# - huggingface/CodeBERTa-small-v1 (CodeBERTa, 768d)
# General purpose models:
# - sentence-transformers/all-MiniLM-L6-v2 (384d, fast)
# - sentence-transformers/all-mpnet-base-v2 (768d, high quality)
# - sentence-transformers/all-distilroberta-v1 (768d, balanced)
EMBEDDING_MODEL=flax-sentence-embeddings/st-codesearch-distilroberta-base
GENERATION_MODEL=microsoft/DialoGPT-medium
MAX_SEQUENCE_LENGTH=512

# Vector Database Configuration
VECTOR_DB_TYPE=chromadb  # Options: chromadb, faiss
VECTOR_DB_PATH=./data/vector_db
COLLECTION_NAME=codebase_embeddings

# Processing Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_WORKERS=4

# Web App Configuration
STREAMLIT_PORT=8501
DEBUG=true

# API Keys (if using external services)
HUGGING_FACE_API_KEY=your_hf_api_key_here
OPENAI_API_KEY=your_openai_api_key_here 